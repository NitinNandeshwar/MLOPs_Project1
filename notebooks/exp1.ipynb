{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "206dcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "248667d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     F:/Programming_Practise/MLOPs_Project1/notebooks...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     F:/Programming_Practise/MLOPs_Project1/notebooks...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# # This will download stopwords if not already present\n",
    "# nltk.download('stopwords') wordNet\n",
    "\n",
    "nltk.download('stopwords', download_dir='F:/Programming_Practise/MLOPs_Project1/notebooks')\n",
    "nltk.download('wordnet', download_dir='F:/Programming_Practise/MLOPs_Project1/notebooks')\n",
    "import nltk.data\n",
    "nltk.data.path.append('F:/Programming_Practise/MLOPs_Project1/notebooks')\n",
    "# nltk.data.path.append('F:/Programming_Practise/MLOPs_Project1/notebooks')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2af49bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>A hilarious and insightful perspective of the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>The Story line for this game is very jerky whe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>This is probably the best cinematic depiction ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>I saw \"Sweeney Todd\" on Broadway in 1980. It s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>I am a massive fan of the book and Orwell is c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "323  A hilarious and insightful perspective of the ...  positive\n",
       "439  The Story line for this game is very jerky whe...  positive\n",
       "914  This is probably the best cinematic depiction ...  positive\n",
       "903  I saw \"Sweeney Todd\" on Broadway in 1980. It s...  positive\n",
       "259  I am a massive fan of the book and Orwell is c...  negative"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"IMDB.csv\")\n",
    "df=df.sample(500)\n",
    "df.to_csv(\"data.csv\",index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d00d1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Define Text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\" Lemmatize the text. \"\"\"\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text=text.split()\n",
    "    text=[lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\" Remove stopswords from the text \"\"\"\n",
    "    stop_words= set(stopwords.words(\"english\"))\n",
    "    text=[word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\" Remove numbers from the text \"\"\"\n",
    "    text= \"\".join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\" Convert text to lower case \"\"\"\n",
    "    text= text.split()\n",
    "    text=[word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctations(text):\n",
    "    \"\"\" Removing puncatations from the text \"\"\"\n",
    "    text= re.sub('[%s]' % re.escape(string.punctuation),' ', text)\n",
    "    text=text.replace(':','')\n",
    "    text=re.sub('\\s+',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\" Remove URLs from the text. \"\"\"\n",
    "    url_pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'',text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\" Normalize the text data.\"\"\"\n",
    "    try: \n",
    "        df[\"review\"]= df[\"review\"].apply(lower_case)\n",
    "        df[\"review\"]= df[\"review\"].apply(remove_stop_words)\n",
    "        df[\"review\"]= df[\"review\"].apply(removing_numbers)\n",
    "        df[\"review\"]= df[\"review\"].apply(removing_punctations)\n",
    "        df[\"review\"]= df[\"review\"].apply(removing_urls)\n",
    "        df[\"review\"]= df[\"review\"].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error during text normalization: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99a51a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>hilarious insightful perspective dating world ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>story line game jerky appears game writer trie...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>probably best cinematic depiction life manhatt...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>saw sweeney todd broadway starred george hearn...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>massive fan book orwell certainly favourite wr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "323  hilarious insightful perspective dating world ...  positive\n",
       "439  story line game jerky appears game writer trie...  positive\n",
       "914  probably best cinematic depiction life manhatt...  positive\n",
       "903  saw sweeney todd broadway starred george hearn...  positive\n",
       "259  massive fan book orwell certainly favourite wr...  negative"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f769b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    264\n",
       "positive    236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa8265eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['sentiment'].isin(['positive','negative'])\n",
    "df=df[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5563c55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>hilarious insightful perspective dating world ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>story line game jerky appears game writer trie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>probably best cinematic depiction life manhatt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>saw sweeney todd broadway starred george hearn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>massive fan book orwell certainly favourite wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "323  hilarious insightful perspective dating world ...          1\n",
       "439  story line game jerky appears game writer trie...          1\n",
       "914  probably best cinematic depiction life manhatt...          1\n",
       "903  saw sweeney todd broadway starred george hearn...          1\n",
       "259  massive fan book orwell certainly favourite wr...          0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']=df['sentiment'].map({'positive':1,'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "206541b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbad99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(max_features=100)\n",
    "X=vectorizer.fit_transform(df['review'])\n",
    "y=df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "813f26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c609cab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Suman\\anaconda3\\envs\\mlops1\\lib\\site-packages\\rich\\live.py:229: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Suman\\anaconda3\\envs\\mlops1\\lib\\site-packages\\rich\\live.py:229: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=1dc423f5-1135-4e04-833e-89b2360f2159&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=e436005a47489d89588779e53fc3b398dc50a4e22f155868ad94d64881dafd8a\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as NitinNandeshwar\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as NitinNandeshwar\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"NitinNandeshwar/MLOPs_Project1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"NitinNandeshwar/MLOPs_Project1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository NitinNandeshwar/MLOPs_Project1 initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository NitinNandeshwar/MLOPs_Project1 initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/28 15:54:46 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/62e8187d480a4b5e812534a8cf4f655d', creation_time=1751122486198, experiment_id='0', last_update_time=1751122486198, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/NitinNandeshwar/MLOPs_Project1.mlflow')\n",
    "dagshub.init(repo_owner='NitinNandeshwar',repo_name='MLOPs_Project1',mlflow=True)\n",
    "\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8aa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure Logging\n",
    "logging.basicConfig(level=logging.INFO,format=\"%(asctime)s - %(levelname)s - %(message)s \")\n",
    "\n",
    "logging.info(\"Starting MLflow run ...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time=time.time()\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters ...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\",100)\n",
    "        mlflow.log_param(\"test_size\", 0.25)\n",
    "\n",
    "        logging.info(\"Initsializing Logistic Regression model ...\")\n",
    "        model= LogisticRegression(max_iter=1000) # Increase max_iter to prevent non-convergences issues\n",
    "\n",
    "        logging.info(\"Fitting the model ...\")\n",
    "        model.fit(X_train,y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model paramters...\")\n",
    "        mlflow.log_param(\"model\",\"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions ...\")\n",
    "        y_pred= model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics ...\")\n",
    "        accuracy=accuracy_score(y_test,y_pred)\n",
    "        precision=precision_score(y_test,y_pred)\n",
    "        recall=recall_score(y_test,y_pred)\n",
    "        f1=f1_score(y_test,y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics ...\")\n",
    "        mlflow.log_metric(\"accuracy\",accuracy)\n",
    "        mlflow.log_metric(\"precision\",precision)\n",
    "        mlflow.log_metric(\"recall\",recall)\n",
    "        mlflow.log_metric(\"f1_score\",f1)\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        # mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # Print the results for verification\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred : {e}\",exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
